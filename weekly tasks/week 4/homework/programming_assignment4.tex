\documentclass[11pt, a4paper]{article}
\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor=blue, breaklinks=true}
\newcommand{\angles}[1]{$\langle$#1$\rangle$}

%%%%% ADD THIS TO YOUR PREAMBLE BEFORE LOADING Alegreya
\DeclareFontFamily{T1}{Alegreya-LF}{}
\newcommand{\adjustalegreya}{\fontdimen5\font=\fontcharht\font`x }
\makeatletter
\let\Alegreya@@scale\@empty
%%% uncomment the next line if you want to scale the font,
%%% changing the value to what suits you
% \def\Alegreya@@scale{s*[0.9]}%
\makeatother

\DeclareFontShape{T1}{Alegreya-LF}{k}{n}{
      <-> \Alegreya@@scale Alegreya-Black-lf-t1
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{k}{it}{
      <-> \Alegreya@@scale Alegreya-BlackItalic-lf-t1
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{k}{sl}{
      <-> ssub * Alegreya-LF/k/it
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{b}{n}{
      <-> \Alegreya@@scale Alegreya-Bold-lf-t1
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{b}{it}{
      <-> \Alegreya@@scale Alegreya-BoldItalic-lf-t1
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{b}{sl}{
      <-> ssub * Alegreya-LF/b/it
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{m}{n}{on the spot
      <-> \Alegreya@@scale Alegreya-Regular-lf-t1
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{m}{it}{
      <-> \Alegreya@@scale Alegreya-Italic-lf-t1
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{m}{sl}{
      <-> ssub * Alegreya-LF/m/it
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{bx}{sl}{
      <-> ssub * Alegreya-LF/b/sl
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{bx}{n}{
      <-> ssub * Alegreya-LF/b/n
}{\adjustalegreya}

\DeclareFontShape{T1}{Alegreya-LF}{bx}{it}{
      <-> ssub * Alegreya-LF/b/it
}{\adjustalegreya}

%%%% NOW YOU CAN SAFELY LOAD Alegreya (don't pass a scale option)
\usepackage{Alegreya}
\usepackage{amsmath}

\title{Programming Assignment 4 -- Basic Probability, Computing and Statistics 2017}
\author{Jakub Dotla\v{c}il and Bas Cornellisen}
\date{Submission deadline: Wednesday, May 2nd, 8 p.m.}

\begin{document}
\maketitle

\paragraph{Note:} if the assignment is unclear to you or if you get stuck, do not hesitate to contact \href{mailto:j.dotlacil@uva.nl}{Jakub} or \href{mailto:bjmcornelissen@gmail.com}{Bas}. You can also post a question on Canvas.

\section{Assignment}

This week we will implement a Na\"ive Bayes (NB) classifier for text data. If you do not remember what a 
NB classifier is, check \href{https://github.com/BasicProbability/LectureNotes/blob/master/chapter4/chapter4.pdf}{here}. 
We will first train the classifier and then make predictions based on our estimates.

\subsection{Na\"ive Bayes Terminology}

In NB training we assume i.i.d. data points $ (x_{i},y_{i}) $ ($ 1 \leq i \leq n $) where $ x_{i} $ is a $ k $-dimensional vector and
$ y $ is 1-dimensional. The entries of $ x $ are called \textbf{features}. When we have to make predictions we are presented with vectors
$ x_{t} $ ($ t > n $) which have no accompanying $ y $-values. Our task is to infer these $ y $-values. The posterior probability of a particular value
for $ Y_{t} $ according the the Na\"ive Bayes assumption is
\begin{equation}
P(Y_{y} = y_{t}|X_{t} = x_{t}) \propto P(Y_{t} = y_{t}) \prod_{j=1}^{k}P(X_{tj} = x_{tj}|Y_{t} = y_{t}) \ .
\end{equation}

By convention, we call the $ Y $-variables \textbf{labels}, \textbf{classes} or \textbf{categories}. We will use these terms interchangeably to get you used
to them. A Naive classifier thus performs inference based on $ k $ features (where $ k $ may differ across data points). For the purpose of this exercise, we take the 
features to be words and the labels to be names of news groups.

\subsection{Data}

We will use the famous \href{http://qwone.com/~jason/20Newsgroups/}{20 newsgroups data set} for this 
exercise. As the name suggest, there are 20 groups of text and our task is to find the right group for given words. This
implies a baseline performance achieved by randomly choosing a group of $ 5\% $. The data are emails
within newsgroups collected in the 1990's. For a start, we will simply use all strings separated by
whitespace as features for our NB model. We call these strings words.

\subsection{Smoothing}

Many words will only occur in one class $ c $. When we see a text from that class during prediction time, the
other classes will not have probabilities for as many words as $ c $. There are two ways to go about this:
\begin{enumerate}
\item Simply ignore the words that have 0 probability under a class. This will lead to many classes
having fewer terms in the NB product than $ c $. Thus, these classes will have a higher posterior.
\item Do model all words for all classes. Unfortunately, most unseen texts (the ones we are dealing
with at prediction time) contain for each class at least one word that has 0 probability. In effect, the
posterior probability for all classes will be 0. Notice that this means the posterior is not even defined
as it does not sum up to 1.
\end{enumerate} 

As you can see, both ways will give us the wrong results. There is a cleverer way, however. We remember
all words that we have encountered during training. These define our vocabulary. During prediction we
will ignore all words not in the vocabulary. Moreover, we perform smoothing. This means that, before running any predictions, we add a constant count for \textit{all} words in the vocabulary to the training counts
of every class. This has the effect that all vocabulary words will have positive probability under
all classes. 

\subsection{Logprobs}

There is one more practical problem we have to solve. When you classify a document, you have to compute a potentially large product of probabilities. These products can become very, very small. In fact, they become so small that our computers won't be able to 
represent them in memory and just turn them into 0.

The standard way to avoid this problem is to work with logarithms of probabilities (logprobs) instead. You should always use logprobs when performing
probabilistic computations! Multiplication and division of probabilities is then straightforward because for positive numbers $ a,b > 0 $ it holds that
\begin{align*}
\log(a \cdot b) &= log(a) + log(b) \\
\log\left( \frac{a}{b} \right) &= log(a) - log(b) \\
\log\left( a^{b} \right) &= \log(a) \cdot b
\end{align*}

Addition and subtraction is slightly more involved. Let $ c = \log(a) $ and $ d = \log(b) $. The na\"ive way to do addition would be through simple exponentiation.
\begin{equation*}
\log(\exp(c) + \exp(d)) = \log(a + b)
\end{equation*}
This is inefficient, however, since we need to compute two exponentials and one logarithm. Computers are slow at that. Instead, the 
following equivalence is exploited. Without loss of generality, we also assume that $ c > d $.
\begin{align*}
\log(\exp(c) + \exp(d)) &= \log(\exp(c) \cdot (1 + \exp(d-c)))  \\
&= c + \log(1 + \exp(d-c)) 
\end{align*}

There are several advantages to using this trick. First, we only compute one exponential and one logarithm. Second, the logarithm computation is already 
implemented in many programming languages (including Python) as a function called \texttt{log1p} (see \href{https://docs.python.org/3/library/math.html}{here} for documentation). The \texttt{log1p} function computes $ \log(1 + \exp(d-c)) $ very efficiently when the exponent is small.

To sum up, you have to avoid turning that joint probabilities turn to 0, and to do so, you have to work with log-probs. Make sure to transform probabilities to log-probs before doing any predictions.

\subsection{Your Task}
We have implemented a commandline interface and a skeleton of the Naive Bayes class for you. Both can be 
found \href{https://github.com/BasicProbability/Programming2018/blob/master/weekly\%20tasks/week\%204/homework/files_for_development.zip}{here}. Do not manipulate \texttt{naive\_bayes\_classifier.py}. Your task is to only work on the methods of the class NaiveBayes, which is in the file naive\_bayes.py. Please implement the methods that are marked with a TODO. For prediction, please output the 
a posteriori most likely label. Feel free to add any methods and data structures that you deem necessary.

\paragraph{Challenge yourself} On the development set, which we provide together with the code, you
should achieve an accuracy of $ 81.05\% $ if the smoothing constant is set to 1. Can you do better
than that? Try different smoothing constants or try to change the words (e.g. by lowercasing them) or
try to include more features (characters, for example). The possibilities are limitless! 

\subsection{Running the Code}
You will have to supply commandline arguments to the script this time. This can be done in Pycharm. 
Right-click on the run symbol and select \textit{Add parameters}. In the field \textit{script parameters}
you then have to enter the following for \texttt{naive\_bayes\_classifier.py}
\begin{center}
\texttt{--training-corpus-dir <Path to 20news-18828> --test-set-directory <Path to dev-set>}
\end{center}
(Note: the line break was inserted by \LaTeX and is not needed in Pycharm.)
You can optionally add
\begin{center}
\texttt{--keys <Path to dev\_key.txt>}
\end{center}
in which case the script will also run an evaluation of your output. For this to work you have to assign
a string containing your Python command (either \texttt{python} or \texttt{python3} for most of you)
to the variable \texttt{my\_python} at the top of the file \texttt{naive\_bayes\_classifier.py}.

The output will be a file called \texttt{predictions.txt}. You can also separately run an evaluation of your output using the
accuracy checker (which is the same script used if you provide the \texttt{--keys} argument above). 
For that, you will have to pass argument to \texttt{accuracy\_checker.py}, as well. These
are simply
\begin{center}
\texttt{<Path to predictions.txt> <Path to dev\_keys.txt>}
\end{center} 

\section{Grading}
You will be graded on a test set that we will make available during peer review. The test set
is structured like the dev set but contains different files.
\begin{itemize}
\item[2 points] The code produces predictions that are in the correct format and assign labels that
it has been trained on (instead of arbitrarily named labels)
\item[2 point] The test-set (not dev-set(!)) accuracy is at least $ 20\% $.
\item[2 point] The test-set (not dev-set(!)) accuracy is at least $ 40\% $.
\item[2 point] The test-set (not dev-set(!)) accuracy is at least $ 60\% $.
\item[1 point] The test-set (not dev-set(!)) accuracy is at least $ 70\% $.
\item[1 point] The test-set (not dev-set(!)) accuracy is higher than $ 80\% $.
\end{itemize}

\end{document}
